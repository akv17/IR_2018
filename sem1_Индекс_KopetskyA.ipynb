{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Семинар 1 Индекс\n",
    "\n",
    "## Intro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### чтение файла \n",
    "- конструкция __with open__ (recommended)\n",
    "- конструкция __open + close__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fpath = 'fpath.txt'\n",
    "\n",
    "# одним массивом  \n",
    "with open(fpath, 'r') as f:  \n",
    "    text = f.read() \n",
    "\n",
    "#по строкам, в конце каждой строки \\n  \n",
    "with open(fpath, 'r') as f:   \n",
    "    text = f.readlines() \n",
    "\n",
    "#по строкам, без \\n   \n",
    "with open(fpath, 'r') as f:   \n",
    "    text = f.read().splitlines() \n",
    "    \n",
    "#not reccomended  \n",
    "file = open(txt_fpath, 'r')  \n",
    "text = file.read()    \n",
    "file.close() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### работа с файлами и папками"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### os.path  \n",
    "путь до файла"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# возвращает полный путь до папки/файла по имени файла / папки\n",
    "print(os.path.abspath('fpath.txt'))\n",
    "\n",
    "# возвращает имя файла / папки по полному пути до него\n",
    "print(os.path.basename('/your/path/to/folder/with/fpath.txt'))\n",
    "\n",
    "# проверить существование директории - True / False\n",
    "print(os.path.exists('your/path/to/any/folder/'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### os.listdir  \n",
    "возвращает список файлов в данной директории"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "main_dir = '/your/path/to/folder/with/folders/'\n",
    "os.listdir(main_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "сделаем пути абсолютными, чтобы наш код не зависел от того, где лежит этот файл"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "[main_dir + fpath for fpath in os.listdir(main_dir)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "не забывайте исключать системные директории, такие как .DS_Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "[main_dir + fpath for fpath in os.listdir(main_dir) if not '.DS_Store' in fpath]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### os.walk\n",
    "root - начальная директория  \n",
    "dirs - список поддиректорий (папок)   \n",
    "files - список файлов в этих поддиректориях  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "main_dir = '/your/path/to/folder/with/folders/'\n",
    "\n",
    "for root, dirs, files in os.walk(main_dir):\n",
    "    for name in files:\n",
    "        print(os.path.join(root, name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> __os.walk__ возвращает генератор, это значит, что получить его элементы можно только проитерировавшись по нему  \n",
    "но его легко можно превратить в list и увидеть все его значения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list(os.walk(main_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Обратный индекс \n",
    "\n",
    "Сам по себе обратный индекс не может осуществлять поиск, для этого необходимо добавить к нему определенную метрику. Это не совсем очевидная задача, поэтому немного отложим ее. А сейчас посмотрим, что полезного можно вытащить из индекса.    \n",
    "По сути, индекс - это информация о частоте встречаемости слова в каждом документе.   \n",
    "Из этого можно понять, например:\n",
    "1. какое слово является самым часто употребимым / редким\n",
    "2. какие слова встречаются всегда вместе. Так можно парсить твиттер, fb, форумы и отлавливать новые устойчивые выражения в речи\n",
    "3. какой документ является самым большим / маленьким (очень изощренный способ, когда есть _len_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __Задача__: \n",
    "получите обратный индекс для коллекция документов.    \n",
    "Перед этим постройте матрицу терм-документ и сделайте функцию булева поиска, которая по запросу будет возвращать 5 релевантных документов.   \n",
    "В качестве коллекции возьмите сценарий сезонов сериала Друзья. Одна серия - один документ.\n",
    "\n",
    "[download_friends_corpus](https://yadi.sk/d/k_M7n63A3adGSz)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Этапы:   \n",
    "    1. получить коллекцию документов\n",
    "    2. для каждого файла коллекции сделать необходимую на ваш взгляд предобработку\n",
    "    3. получить матрицу терм-документ, написать функцию поиска по ней\n",
    "    4. получить обратный индекс в виде словаря, где ключ - нормализованное слово, \n",
    "    значение - список файлов, в которых это слово встречается\n",
    "    5. вывести кусочек индекса в виде таблицы \n",
    "    6. сделать анализ обратного индекса. Это задание принимается в виде кода и ответов на вопросы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](Friends/wedding.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Напоминание:    \n",
    "> При итерации по списку вы можете помимо самого элемента получить его порядковый номер    \n",
    "``` for i, element in enumerate(your_list): ...  ```    \n",
    "Иногда для получения элемента делают так -  ``` your_list[i] ```, старайтесь этого избегать"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "STOPWORDS = stopwords.words('russian')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "main_dir = 'Friends'\n",
    "files_list = []\n",
    "\n",
    "### пройдитесь по всем папкам коллекции и соберите все пути .txt файлов\n",
    "### _check : в коллекции должно быть 165 файлов\n",
    "\n",
    "for root, dirs, files in os.walk(main_dir):\n",
    "    if files:\n",
    "        files_list.extend([os.path.join(root, f) for f in files if not '.DS_Store' in f])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "assert len(files_list) == 165"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalize(doc):\n",
    "    \"\"\"\n",
    "    doc: <str>\n",
    "    return: <str>\n",
    "    \"\"\"\n",
    "    \n",
    "    return ' '.join([re.sub('[\\W]', '', word.lower()) for word in doc.split() if word.lower() not in STOPWORDS])\n",
    "\n",
    "def build_doc_collection_from_files(paths, normalization_func=None):\n",
    "    \n",
    "    def _read(path):\n",
    "        \"\"\"\n",
    "        return: <str>\n",
    "        \"\"\"\n",
    "        \n",
    "        with open(path, 'r', encoding='utf-8-sig') as f:  \n",
    "            return ' '.join(f.readlines()[:-3]) \n",
    "        \n",
    "    if not normalization_func:\n",
    "        return [_read(path) for path in paths]\n",
    "    \n",
    "    else:\n",
    "        return [normalization_func(_read(path)) for path in paths]\n",
    "    \n",
    "def build_word_2_idx_from_collection(collection):\n",
    "    word2idx = dict()\n",
    "    _idx = 0\n",
    "    \n",
    "    for doc in collection:\n",
    "        for word in doc.split():\n",
    "            \n",
    "            if word not in word2idx:\n",
    "                word2idx[word] = _idx\n",
    "                _idx += 1\n",
    "                \n",
    "    return word2idx\n",
    "\n",
    "def build_term_doc_matrix_from_collection(collection, word2idx):\n",
    "    \"\"\"\n",
    "    collection: List[<str>]\n",
    "    word2idx: <dict>\n",
    "    \n",
    "    return: np.array[words x docs]\n",
    "    \"\"\"\n",
    "    \n",
    "    matrix = np.zeros([len(word2idx), len(collection)])\n",
    "    \n",
    "    for i, doc in enumerate(collection):\n",
    "        for word in doc.split():\n",
    "            matrix[word2idx[word], i] += 1\n",
    "            \n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нормализованная коллекция"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "COLLECTION = build_doc_collection_from_files(files_list,\n",
    "                                             normalization_func=normalize\n",
    "                                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "assert len(COLLECTION) == 165"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Отображения для индексирования слов и документов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "WORD2IDX = build_word_2_idx_from_collection(COLLECTION)\n",
    "DOC2IDX = {doc: i for i, doc in enumerate(COLLECTION)}\n",
    "IDX2DOC = {i: doc for i, doc in enumerate(COLLECTION)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### постройте матрицу терм-документ\n",
    "term_doc_matrix = build_term_doc_matrix_from_collection(COLLECTION, WORD2IDX)\n",
    "\n",
    "\n",
    "### напишите функцию булева поиска по построенной матрице\n",
    "\n",
    "# модуль для парсинга булева выражения\n",
    "# pip install boolean.py\n",
    "import boolean\n",
    "\n",
    "\n",
    "def boolean_search(matrix, query, n=5) -> list:\n",
    "    \"\"\"\n",
    "    Produces a Boolean search according with the term-document matrix\n",
    "    :return: list of first 5 relevant documents ids\n",
    "    \"\"\"\n",
    "    \n",
    "    def get_set(arg):\n",
    "        return set([i for i, x in enumerate(matrix[WORD2IDX[arg.obj.lower()]]) if x > 0])\n",
    "        \n",
    "    def _not(_set, x):\n",
    "        return set(range(matrix.shape[1])).difference(x)\n",
    "    \n",
    "    def _and(_set, x):\n",
    "        return _set.intersection(x)\n",
    "    \n",
    "    def _or(_set, x):\n",
    "        return _set.union(x)\n",
    "        \n",
    "    def solve(op):\n",
    "        q = list()\n",
    "        \n",
    "        if 'AND' in str(type(op)):\n",
    "            op_func = _and\n",
    "            \n",
    "        elif 'OR' in str(type(op)):\n",
    "            op_func = _or\n",
    "        \n",
    "        else:\n",
    "            op_func = _not\n",
    "        \n",
    "        # print('OP', op_func.__name__)\n",
    "        # print('args', op.args)\n",
    "        \n",
    "        for arg in op.args:\n",
    "            if 'Symbol' in str(type(arg)):\n",
    "                q.append(get_set(arg))\n",
    "            else:\n",
    "                q.append(solve(arg))\n",
    "        \n",
    "        _set = q[0]\n",
    "        \n",
    "        for el in q:\n",
    "            _set = op_func(_set, el)\n",
    "        \n",
    "        # print('returning set', _set)\n",
    "        \n",
    "        return _set\n",
    "    \n",
    "    query = re.sub('&', 'AND', query)\n",
    "    query = re.sub('ИЛИ', 'OR', query)\n",
    "    query = re.sub('НЕ', 'NOT', query)\n",
    "    \n",
    "    alg = boolean.BooleanAlgebra()\n",
    "    exp = alg.parse(query)\n",
    "    \n",
    "    if 'Symbol' in str(type(exp)):\n",
    "        return get_set(exp)\n",
    "    \n",
    "    return list(solve(exp))[:n]\n",
    "\n",
    "\n",
    "#запросы \n",
    "input_text = [\n",
    "    'Моника & Фиби & Рэйчел & Чендлер & Джои & Росс',\n",
    "    '(Моника ИЛИ Фиби) & Рэйчел & (Чендлер ИЛИ Джои) & Росс', \n",
    "    '(НЕ Моника) & Фиби & Рэйчел & Чендлер & Джои & (НЕ Росс)'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Часть матрицы терм-документ в виде таблицы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_0</th>\n",
       "      <th>doc_1</th>\n",
       "      <th>doc_2</th>\n",
       "      <th>doc_3</th>\n",
       "      <th>doc_4</th>\n",
       "      <th>doc_5</th>\n",
       "      <th>doc_6</th>\n",
       "      <th>doc_7</th>\n",
       "      <th>doc_8</th>\n",
       "      <th>doc_9</th>\n",
       "      <th>...</th>\n",
       "      <th>doc_155</th>\n",
       "      <th>doc_156</th>\n",
       "      <th>doc_157</th>\n",
       "      <th>doc_158</th>\n",
       "      <th>doc_159</th>\n",
       "      <th>doc_160</th>\n",
       "      <th>doc_161</th>\n",
       "      <th>doc_162</th>\n",
       "      <th>doc_163</th>\n",
       "      <th>doc_164</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>друзья</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>началось</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>нечего</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>рассказывать</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>просто</th>\n",
       "      <td>20.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 165 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              doc_0  doc_1  doc_2  doc_3  doc_4  doc_5  doc_6  doc_7  doc_8  \\\n",
       "друзья          1.0    0.0    3.0    0.0    2.0    0.0    0.0    0.0    0.0   \n",
       "началось        2.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "нечего          1.0    0.0    0.0    0.0    1.0    0.0    0.0    0.0    0.0   \n",
       "рассказывать    1.0    1.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "просто         20.0    5.0    8.0    3.0   11.0   11.0    9.0    9.0    4.0   \n",
       "\n",
       "              doc_9   ...     doc_155  doc_156  doc_157  doc_158  doc_159  \\\n",
       "друзья          0.0   ...         0.0      0.0      1.0      0.0      0.0   \n",
       "началось        0.0   ...         0.0      0.0      1.0      0.0      0.0   \n",
       "нечего          0.0   ...         0.0      0.0      1.0      0.0      1.0   \n",
       "рассказывать    0.0   ...         0.0      0.0      0.0      0.0      0.0   \n",
       "просто          6.0   ...         5.0      6.0      2.0      2.0      3.0   \n",
       "\n",
       "              doc_160  doc_161  doc_162  doc_163  doc_164  \n",
       "друзья            0.0      2.0      1.0      1.0      1.0  \n",
       "началось          0.0      0.0      1.0      0.0      0.0  \n",
       "нечего            0.0      0.0      0.0      0.0      0.0  \n",
       "рассказывать      0.0      0.0      1.0      0.0      1.0  \n",
       "просто            8.0      2.0      3.0      3.0      5.0  \n",
       "\n",
       "[5 rows x 165 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(term_doc_matrix,\n",
    "             index=list(WORD2IDX.keys()),\n",
    "             columns=['doc_%s' % i for i, doc in enumerate(COLLECTION)]\n",
    "            ).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Булев поиск по заданным запросам (возвращается список айди релевантных документов)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query: Моника & Фиби & Рэйчел & Чендлер & Джои & Росс\n",
      "found: [0, 3, 6, 13, 21]\n",
      "\n",
      "query: (Моника ИЛИ Фиби) & Рэйчел & (Чендлер ИЛИ Джои) & Росс\n",
      "found: [0, 1, 3, 4, 6]\n",
      "\n",
      "query: (НЕ Моника) & Фиби & Рэйчел & Чендлер & Джои & (НЕ Росс)\n",
      "found: []\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for query in input_text:\n",
    "    print('query: %s\\nfound: %s\\n' % (query, boolean_search(term_doc_matrix, query)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим, например, документ 6 по второму запросу"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    ('моника' in COLLECTION[6] or 'фиби' in COLLECTION[6]) and 'рэйчел' in COLLECTION[6] \\\n",
    "    and ('чендлер' in COLLECTION[6] or 'джои' in COLLECTION[6]) and 'росс' in COLLECTION[6]\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"pics/inv_index3.svg\" alt=\"Drawing\" style=\"width: 600px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Совет для построения обратного индекса: \n",
    "> В качестве словаря используйте ``` defaultdict ``` из модуля collections   \n",
    "Так можно избежать конструкции ``` dict.setdefault(key, default=None) ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def inverted_index(collection) -> dict:\n",
    "    \"\"\"\n",
    "    Create inverted index by input doc collection\n",
    "    :return: inverted index\n",
    "    \"\"\"\n",
    "    inv_idx = defaultdict(dict)\n",
    "    \n",
    "    for i, doc in enumerate(collection):\n",
    "        for word in doc.split():\n",
    "            \n",
    "            if inv_idx[word].get(i) is None:\n",
    "                inv_idx[word][i] = 1\n",
    "            \n",
    "            else:\n",
    "                inv_idx[word][i] += 1\n",
    "                \n",
    "    for word in inv_idx.keys():\n",
    "        inv_idx[word] = [(doc, freq) for doc, freq in inv_idx[word].items()]\n",
    "                \n",
    "    return inv_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обратный индекс, включающий частотность по документам вида `(doc_id, freq)` <i>[для выполнения последующих пунктов]</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "INV_IDX = inverted_index(COLLECTION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Часть обратного индекса в виде таблицы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>documents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>друзья</th>\n",
       "      <td>[(0, 1), (2, 3), (4, 2), (10, 1), (11, 1), (12...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>началось</th>\n",
       "      <td>[(0, 2), (61, 1), (64, 1), (72, 2), (89, 1), (...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>нечего</th>\n",
       "      <td>[(0, 1), (4, 1), (24, 1), (31, 1), (37, 1), (3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>рассказывать</th>\n",
       "      <td>[(0, 1), (1, 1), (18, 1), (32, 1), (45, 1), (4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>просто</th>\n",
       "      <td>[(0, 20), (1, 5), (2, 8), (3, 3), (4, 11), (5,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      documents\n",
       "друзья        [(0, 1), (2, 3), (4, 2), (10, 1), (11, 1), (12...\n",
       "началось      [(0, 2), (61, 1), (64, 1), (72, 2), (89, 1), (...\n",
       "нечего        [(0, 1), (4, 1), (24, 1), (31, 1), (37, 1), (3...\n",
       "рассказывать  [(0, 1), (1, 1), (18, 1), (32, 1), (45, 1), (4...\n",
       "просто        [(0, 20), (1, 5), (2, 8), (3, 3), (4, 11), (5,..."
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "INV_IDX_DF = pd.DataFrame.from_dict({word: [docs] for word, docs in INV_IDX.items()}, orient='index')\n",
    "INV_IDX_DF.columns = ['documents']\n",
    "INV_IDX_DF.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "С помощью обратного индекса произведите следующую аналитику:  \n",
    "\n",
    "1) общая аналитика\n",
    "- какое слово является самым частотным?\n",
    "- какое самым редким?\n",
    "- какой набор слов есть во всех документах коллекции?\n",
    "\n",
    "2) частота встречаемости имен главных героев в каждом сезоне      \n",
    "- какой сезон был самым популярным у Чендлера? у Моники?   \n",
    "- кто из главных героев статистически самый популярный? \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Общая аналитика"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "WORD_FREQ_SORTED = sorted(INV_IDX,\n",
    "                           key=lambda x: sum([freq for doc, freq in INV_IDX[x]]),\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Самое частотное слово: это\n",
      "Самое редкое слово: сотрудник\n",
      "Набор слов, встречающихся во всех документах: ['просто', 'тебе', 'это', 'да', 'нет', 'что']\n"
     ]
    }
   ],
   "source": [
    "print('Самое частотное слово: %s\\nСамое редкое слово: %s\\nНабор слов, встречающихся во всех документах: %s' %\n",
    "        (WORD_FREQ_SORTED[-1],\n",
    "         WORD_FREQ_SORTED[0],\n",
    "        [word for word in INV_IDX.keys() if len(INV_IDX[word]) == 165]\n",
    "        )\n",
    "     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Частота встречаемости имен главных героев в каждом сезоне"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_word_freq_per_season(word, inv_idx, print_out=False):\n",
    "    freqs = dict()\n",
    "    \n",
    "    for season in SEASON_MASK.keys():\n",
    "        freqs[season] = sum([freq for doc, freq in INV_IDX[word] if doc in SEASON_MASK[season]])\n",
    "        \n",
    "    if print_out:\n",
    "        print('\"%s\"\\n\\nСезон: Частота' % word)\n",
    "        \n",
    "        for season in sorted(freqs, key=freqs.get, reverse=True):\n",
    "            print('%s: %s' % (season, freqs[season]))\n",
    "                            \n",
    "    return freqs\n",
    "\n",
    "\n",
    "def get_top_freq_word_per_season(words, inv_idx, print_out=False):\n",
    "    words_freq = dict()\n",
    "    seasons_freq = dict()\n",
    "    \n",
    "    for word in words:\n",
    "        word_freq = get_word_freq_per_season(word, inv_idx)\n",
    "        words_freq[word] = word_freq\n",
    "    \n",
    "    for season in SEASON_MASK.keys():\n",
    "        seasons_freq[season] = max([(word, words_freq[word][season]) for word in words], key=lambda x: x[1])\n",
    "    \n",
    "    if print_out:\n",
    "        print('Сезон: Самое частотное слово')\n",
    "        for season, word in seasons_freq.items():\n",
    "            print('%s: %s (%s)' % (season, *word))\n",
    "    \n",
    "    return seasons_freq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Отображение сезон-документы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SEASON_MASK = defaultdict(list)\n",
    "\n",
    "for i, f in enumerate(files_list):\n",
    "    SEASON_MASK[int(re.search('season ([\\d])', f).group(1))].append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"чендлер\"\n",
      "\n",
      "Сезон: Частота\n",
      "6: 108\n",
      "5: 105\n",
      "7: 91\n",
      "4: 74\n",
      "3: 58\n",
      "1: 48\n",
      "2: 48\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{1: 48, 2: 48, 3: 58, 4: 74, 5: 105, 6: 108, 7: 91}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_word_freq_per_season('чендлер', INV_IDX, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Самый популярный сезон у Чендлера - 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"моника\"\n",
      "\n",
      "Сезон: Частота\n",
      "5: 93\n",
      "7: 86\n",
      "6: 82\n",
      "2: 64\n",
      "3: 56\n",
      "1: 46\n",
      "4: 44\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{1: 46, 2: 64, 3: 56, 4: 44, 5: 93, 6: 82, 7: 86}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_word_freq_per_season('моника', INV_IDX, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Самый популярный сезон у Моники - 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Список чаще всего упоминаемых героев по сезонам"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Сезон: Самое частотное слово\n",
      "1: рэйчел (67)\n",
      "2: росс (102)\n",
      "3: росс (90)\n",
      "4: джоуи (124)\n",
      "5: росс (167)\n",
      "6: росс (140)\n",
      "7: джоуи (157)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{1: ('рэйчел', 67),\n",
       " 2: ('росс', 102),\n",
       " 3: ('росс', 90),\n",
       " 4: ('джоуи', 124),\n",
       " 5: ('росс', 167),\n",
       " 6: ('росс', 140),\n",
       " 7: ('джоуи', 157)}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_top_freq_word_per_season(['чендлер', 'фиби', 'моника', 'росс', 'рэйчел', 'джоуи'], INV_IDX, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Итого, наиболее популярным является Росс, будучи самым часто упоминаемым в 4 сезонах: 2, 3, 5, 6  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Функция ранжирования Okapi BM25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для обратного индекса есть общепринятая формула для ранжирования *Okapi best match 25* ([Okapi BM25](https://ru.wikipedia.org/wiki/Okapi_BM25)).    \n",
    "Пусть дан запрос $Q$, содержащий слова  $q_1, ... , q_n$, тогда функция BM25 даёт следующую оценку релевантности документа $D$ запросу $Q$:\n",
    "\n",
    "$$ score(D, Q) = \\sum_{i}^{n} \\text{IDF}(q_i)*\\frac{(k_1+1)*f(q_i,D)}{f(q_i,D)+k_1(1-b+b\\frac{|D|}{avgdl})} $$ \n",
    "где   \n",
    ">$f(q_i,D)$ - частота слова $q_i$ в документе $D$ (TF)       \n",
    "$|D|$ - длина документа (количество слов в нём)   \n",
    "*avgdl* — средняя длина документа в коллекции    \n",
    "$k_1$ и $b$ — свободные коэффициенты, обычно их выбирают как $k_1$=2.0 и $b$=0.75   \n",
    "$$$$\n",
    "$\\text{IDF}(q_i)$ есть обратная документная частота (IDF) слова $q_i$: \n",
    "$$\\text{IDF}(q_i) = \\log\\frac{N-n(q_i)+0.5}{n(q_i)+0.5},$$\n",
    ">> где $N$ - общее количество документов в коллекции   \n",
    "$n(q_i)$ — количество документов, содержащих $q_i$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### реализуйте эту функцию ранжирования \n",
    "from math import log\n",
    "\n",
    "k1 = 2.0\n",
    "b = 0.75\n",
    "\n",
    "def score_BM25(qf, dl, avgdl, k1, b, N, n) -> float:\n",
    "    \"\"\"\n",
    "    Compute similarity score between search query and documents from collection\n",
    "    :return: score\n",
    "    \"\"\"\n",
    "    \n",
    "    return log((N - n + 0.5) / (n + 0.5)) * ((k1 + 1) * qf) / (qf + k1 * (1 - b + b * (dl / avgdl)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __Задача__:    \n",
    "напишите функцию, которая сортирует поисковую выдачу для любого входящего запроса согласно метрике *Okapi BM25*.    \n",
    "Выведите 10 первых результатов и их скор по запросу **рождественские каникулы**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "avgdl = np.mean([len(doc.split()) for doc in COLLECTION])\n",
    "N = 165"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_sim(query, document_id) -> float:\n",
    "    \"\"\"\n",
    "    Compute similarity score between search query and documents from collection\n",
    "    :return: score\n",
    "    \"\"\"\n",
    "    score = 0\n",
    "    dl = len(IDX2DOC[document_id].split())\n",
    "    \n",
    "    for word in query.split():\n",
    "        qf = term_doc_matrix[WORD2IDX[word], document_id]\n",
    "        n = len(INV_IDX[word])\n",
    "        score += score_BM25(qf, dl, avgdl, k1, b, N, n)\n",
    "    \n",
    "    return score\n",
    "\n",
    "\n",
    "def get_search_result(query, collection, inv_idx) -> list:\n",
    "    \"\"\"\n",
    "    Compute sim score between search query and all documents in collection\n",
    "    Collect as pair (doc_id, score)\n",
    "    :param query: input text\n",
    "    :return: list of lists with (doc_id, score)\n",
    "    \"\"\"\n",
    "    scores = list()\n",
    "    \n",
    "    for i, doc in enumerate(collection):\n",
    "        scores.append((i, compute_sim(query, i)))\n",
    "        \n",
    "    return sorted(scores, key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выдача по данному запросу"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(134, 6.666618528089834),\n",
       " (29, 6.400140144372682),\n",
       " (16, 5.533527536171587),\n",
       " (15, 5.450978086258132),\n",
       " (150, 3.8397198506472123),\n",
       " (70, 3.6740733876352056),\n",
       " (124, 3.624984565556023),\n",
       " (0, 0.0),\n",
       " (1, 0.0),\n",
       " (2, 0.0)]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_search_result('рождественские каникулы', COLLECTION, INV_IDX)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "С помощью обратного индекса легко видеть, что не существует документов, в которых встречается вхождение \"рождественские каникулы\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(15, 2), (16, 2), (29, 3), (70, 1)]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "INV_IDX['рождественские']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(124, 1), (134, 3), (150, 1)]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "INV_IDX['каникулы']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Из чего следует, что по итогам ранжирования вверху должны оказаться документы, содержащие либо \"рождественские\", либо \"каникулы\"<br>\n",
    "Так и есть, видно, например, что в соответствии с используемой ф-ей ранжирования наиболее релевантен документ, в который \"каникулы\" входит трижды, а следующим релевантным документом оказывается тот, в который трижды входит \"рождественские\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
