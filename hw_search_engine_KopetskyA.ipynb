{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ДЗ по поиску\n",
    "\n",
    "Привет! Вам надо реализивать поисковик на базе вопросов-ответов с сайта [pravoved.ru](https://pravoved.ru/questions-archive/).        \n",
    "Поиск должен работать на трех технологиях:       \n",
    "1. обратном индексе     \n",
    "2. word2vec         \n",
    "3. doc2vec      \n",
    "\n",
    "Вы должны понять, какой метод и при каких условиях эксперимента на этом корпусе работает лучше.          \n",
    "Для измерения качества поиска найдите точность (accuracy) выпадания правильного ответа на конкретный вопрос (в этой базе у каждого вопроса есть только один правильный ответ). Точность нужно измерить для всей базы.    \n",
    "При этом давайте считать, что выпал правильный ответ, если он попал в **топ-5** поисковой выдачи.\n",
    "\n",
    "> Сделайте ваш поиск максимально качественным, чтобы значение точности стремилось к 1.     \n",
    "Для этого можно поэкспериментировать со следующим:       \n",
    "- модель word2vec (можно брать любую из опен сорса или обучить свою)\n",
    "- способ получения вектора документа через word2vec: простое среднее арифметическое или взвешивать каждый вектор в соответствии с его tf-idf      \n",
    "- количество эпох у doc2vec (начинайте от 100)\n",
    "- предобработка документов для обучения doc2vec (удалять / не удалять стоп-слова)\n",
    "- блендинг методов поиска: соединить результаты обратного индекса и w2v, или (что проще) w2v и d2v\n",
    "\n",
    "На это задание отведем 10 дней. Дэдлайн сдачи до полуночи 12.10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('qa_corpus.pkl', 'rb') as file:\n",
    "    qa_corpus_paired = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "qa_corpus = [doc for pair in qa_corpus_paired for doc in pair]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "QUERIES = qa_corpus[0:2768:2]\n",
    "RESPONSES = qa_corpus[1:2768:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Всего в корпусе 1384 пары вопрос-ответ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1384"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(qa_corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Первый элемент блока это вопрос, второй - ответ на него"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\nДобрый день.Мой сын гражданин Украины (ДНР),имеет вид на жительство в Р.Ф., кот.получил проживая с 2014 г. в Нижегородской области.В 2017г. переехал на постоянное место жительство в г.Ростов.Официально трудоустроился на одно из промышл.предприятий г.Ростова.Оформил временную регистрацию в Ростове.В УФМС предупредили,что по истечении 90 дней он должен либо постоянно прописаться либо покинуть территорию России.Прошу проконсультировать как быть дальше.(Вернуться домой в Донецк,но здесь идет война,работы нет.В Ростове он работает по специальности.Он инженер машиностроитель.)Временная прописка до 15 марта.  Если он сможет приобрести какую либо недвижимость,как долго будет решаться вопрос о его постоянной прописке в Ростове.Как в этом случае будет решаться вопрос с видом на жительство в Ростове? Не получится ли ,что приобретя квартиру,он не успеет в ней прописаться до окончании срока временной регистрации. С уважением Людмила Евгеньевна.\\n',\n",
       " 'Добрый вечер!Из Вашего вопроса вообще ничего не ясно.Ваш сын по ВНЖ в Нижегородской обл. сделал временную\\xa0 на 90 дней в Ростове? Так? Или в чем заключается вопрос?С ув., АлёнаМиграционный юристРостов-на-Дону ']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa_corpus[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PC\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:1212: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from gensim.models import Word2Vec, Doc2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для эффективной лемматизации я решил написать небольшое собственное API для исполняемого `MyStem.exe`, потому как доступный под windows модуль `pymystem3` работает невероятно не эффективно\n",
    "\n",
    "Кратко:\n",
    "- `MyStem.run(documents, flags, [, parse_mystem_output, pos_tags])`: исполняет `MyStem.exe` с заданными флагами `flags` для коллекции `documents`\n",
    "    - `documents: List[<str>]`: коллекция документов\n",
    "    - `flags: <str>`: флаги\n",
    "    - `parse_mystem_output: <bool>`: привести исполненную выдачу к исходному виду коллекции (адекватный результат на наборе флагов, отличных от объявленных в коде, не гарантируется, но возможен при написании соответствующего парсера)\n",
    "    - `pos_tags: <bool>`: включить POS разметку"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MyStem:\n",
    "    \n",
    "    def __init__(self, exec_path=None):\n",
    "        \"\"\"\n",
    "        exec_path: path to mystem executable\n",
    "        \"\"\"\n",
    "        self.EXEC_PATH = '' if exec_path is None else exec_path\n",
    "    \n",
    "        self.TMP_IN = 'tmp_in'\n",
    "        self.TMP_OUT = 'tmp_out'\n",
    "        \n",
    "        self.SEP = '::SEP::'\n",
    "        \n",
    "    def __export_to_tmp(self, documents):\n",
    "        with open(self.TMP_IN, 'w', encoding='utf-8') as tmp:\n",
    "            tmp.write(self.SEP.join(documents))\n",
    "            \n",
    "    def __read_tmp(self):\n",
    "        with open(self.TMP_OUT, 'r', encoding='utf-8') as tmp:\n",
    "            return tmp.read()\n",
    "        \n",
    "    def __run_exec(self, flags):\n",
    "        os.system('mystem %s %s %s' % (flags, self.TMP_IN, self.TMP_OUT))\n",
    "    \n",
    "    def __parser(self, raw_output, pos_tags):\n",
    "        def parse_word_token(token):\n",
    "            try:\n",
    "                lemma, pos = re.split('\\?=|=|\\?\\?', token)[:2]\n",
    "            except ValueError:\n",
    "                lemma = re.split('\\?=|=|\\?\\?', token)[0]\n",
    "                pos = ''\n",
    "            \n",
    "            lemma = re.sub('[\\W]|_|u', '', lemma)\n",
    "            \n",
    "            if pos:\n",
    "                pos = pos.split(',')[0]\n",
    "            else:\n",
    "                pos = 'UNKN'\n",
    "\n",
    "            if pos_tags:\n",
    "                return '%s_%s' % (lemma, pos)\n",
    "\n",
    "            else:\n",
    "                return lemma\n",
    "\n",
    "        def parse_non_word_token(token):\n",
    "            token = re.sub('::', '', token)\n",
    "            token = re.sub('_', '', token)\n",
    "            return token\n",
    "\n",
    "        parsed = list()\n",
    "        \n",
    "        for doc in raw_output.split('SEP??'):\n",
    "            doc_parsed = list()\n",
    "            \n",
    "            for token in re.split('\\\\\\\\n|\\\\\\\\r|\\\\n|\\\\r', doc):\n",
    "                if re.search('[A-Za-zА-ЯаяёЁ0-9]', token) is not None:\n",
    "                    doc_parsed.append(parse_word_token(token))\n",
    "                \n",
    "                else:\n",
    "                    doc_parsed.append(parse_non_word_token(token))\n",
    "            \n",
    "            parsed.append(' '.join(doc_parsed).strip())\n",
    "        \n",
    "        return parsed\n",
    "    \n",
    "    def __standartize_flags(self, flags):\n",
    "        flags = re.sub('[\\-ds]', '', flags)\n",
    "        return ''.join(sorted(flags))\n",
    "    \n",
    "    def run(self, documents, flags='-idlnc', parse_mystem_output=True, pos_tags=False):\n",
    "        self.__export_to_tmp(documents)\n",
    "        self.__run_exec(flags)\n",
    "        \n",
    "        if parse_mystem_output:\n",
    "            return self.__parser(self.__read_tmp(), pos_tags)\n",
    "        \n",
    "        else:\n",
    "            return self.__read_tmp()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mystem = MyStem()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Лемматизация корпуса"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 8.51 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "qa_corpus_lem = mystem.run(qa_corpus)               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "QUERIES_LEM = qa_corpus_lem[0:2768:2]\n",
    "RESPONSES_LEM = qa_corpus_lem[1:2768:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для построения непосредственно поисковика я реализовал два типа: `<TextUnit>` и `<Corpus>`.<br>\n",
    "Тип `<TextUnit>`: моделирует фрагмент документа / документ, инкапсулируя ряд его атрибутов как альтернатива предложенному на занятии методу с использованием json.<br>\n",
    "Тип `<Corpus>`: реализует корпус документов с возможностью поиска.<br>\n",
    "Интерфейс:<br>\n",
    "- `Corpus.build(documents)`: собрать корпус из документов в `documents`\n",
    "- `Corpus.search(query, top_n, algo, split_by)`: произвести поиск по запросу `query`\n",
    "    - `query: <str>`: запрос\n",
    "    - `top_n: <int>`: размер выдачи\n",
    "    - `algo: <str>`: алгоритм поиска\n",
    "    - `split_by: <str>`: метод разбиения входящего запроса "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class TextUnit:\n",
    "    \n",
    "    def __init__(self, _id, doc_id, chunk_id=-1, text=''):\n",
    "        self._id = _id\n",
    "        self.doc_id = doc_id\n",
    "        self.chunk_id = chunk_id\n",
    "        self.text = text\n",
    "        self.len = len(self.text.split())\n",
    "        \n",
    "        self.w2v = None\n",
    "        self.d2v = None\n",
    "        \n",
    "    def __str__(self):\n",
    "        return 'TextUnit(id=%s, doc_id=%s, chunk_id=%s)' % (self._id,\n",
    "                                                           self.doc_id,\n",
    "                                                           self.chunk_id\n",
    "                                                          )\n",
    "    \n",
    "    __repr__ = __str__\n",
    "    \n",
    "    @staticmethod\n",
    "    def from_text(text):\n",
    "        return TextUnit(-1, -1, -1, text=text)\n",
    "    \n",
    "    def set_w2v(self, model):\n",
    "        vectors = list()\n",
    "        \n",
    "        for word in self.text.split():\n",
    "            if word in model.wv:\n",
    "                vectors.append(model.wv[word])\n",
    "        \n",
    "        if vectors:\n",
    "            self.w2v = np.mean(np.array(vectors), axis=0)\n",
    "        else:\n",
    "            self.w2v = np.random.normal(scale=0.01, size=[model.vector_size,])\n",
    "        \n",
    "        del vectors\n",
    "        \n",
    "    def set_d2v(self, model):\n",
    "        self.d2v = model.infer_vector(self.text.split())\n",
    "        \n",
    "        \n",
    "class Corpus:\n",
    "    \"\"\"\n",
    "    normalize: bool: apply text normalization\n",
    "    to_lower: bool: apply text lowering\n",
    "    split_by: [None, 'sentences', 'words']: chunkize text by sentences, words if not None\n",
    "    n_chunks: int: number of units per each chunk:\n",
    "                    e.g. setting `split_by` = `sentences` and `n_chunks` = `5`\n",
    "                         would chunkize each document into fragments of 5 sentences\n",
    "    w2v_model: Model: model to infer w2v vectors\n",
    "    d2v_model: Model: model to infer d2v vectors\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, normalize=True,\n",
    "                 to_lower=True,\n",
    "                 split_by=None,\n",
    "                 n_chunks=5,\n",
    "                 w2v_model=None,\n",
    "                 d2v_model=None):\n",
    "        \n",
    "        self.normalize = normalize\n",
    "        self.to_lower = to_lower\n",
    "        self.split_by = split_by\n",
    "        self.n_chunks = n_chunks\n",
    "        self.w2v_model = w2v_model\n",
    "        self.d2v_model = d2v_model\n",
    "        \n",
    "        self.__SPLITTERS_MAP = {'sentences': self.__split_sentences,\n",
    "                                'words': self.__split_words}\n",
    "        \n",
    "        self.__ALGOS_SIM_MAP = {'bm25': self.__sim_bm25,\n",
    "                                'w2v': self.__sim_cosine,\n",
    "                                'd2v': self.__sim_cosine,\n",
    "                                'blend': self.__sim_blend}\n",
    "        \n",
    "        self.__ALGOS_CHECK_MAP = {'bm25': self.__check_bm25,\n",
    "                                  'w2v': self.__check_w2v,\n",
    "                                  'd2v': self.__check_d2v,\n",
    "                                  'blend': self.__check_blend}\n",
    "        \n",
    "    def __normalizer(self, text):\n",
    "        text = text.lower() if self.to_lower else text\n",
    "        \n",
    "        if not self.normalize:\n",
    "            return text\n",
    "        \n",
    "        text_norm = list()\n",
    "        \n",
    "        for word in text.split():\n",
    "            word_norm = re.sub('[\\W]|[\\d]|_|u', '', word)\n",
    "            \n",
    "            if word_norm:\n",
    "                text_norm.append(word_norm)\n",
    "        \n",
    "        return ' '.join(text_norm)\n",
    "    \n",
    "    def __split_sentences(self, text):\n",
    "        sents = sent_tokenize(text)\n",
    "        \n",
    "        i = 0\n",
    "        j = self.n_chunks\n",
    "\n",
    "        while i < len(sents):\n",
    "            chunk = ' '.join(sents[i:j])\n",
    "            chunk = self.__normalizer(chunk)\n",
    "            \n",
    "            if chunk:\n",
    "                yield chunk\n",
    "            \n",
    "            i += self.n_chunks\n",
    "            j += self.n_chunks\n",
    "\n",
    "\n",
    "    def __split_words(self, text):\n",
    "        i = 0\n",
    "        j = self.n_chunks\n",
    "        \n",
    "        text = self.__normalizer(text)\n",
    "        _split = text.split()\n",
    "\n",
    "        while i < len(_split):\n",
    "            chunk = _split[i:j]\n",
    "            chunk.extend(['NULL' for _ in range(self.n_chunks - len(chunk))])\n",
    "            chunk = ' '.join(chunk)\n",
    "            \n",
    "            if chunk:\n",
    "                yield chunk\n",
    "\n",
    "            i += self.n_chunks\n",
    "            j += self.n_chunks\n",
    "    \n",
    "    def build(self, documents):\n",
    "        self.D = list()\n",
    "        self.DOCS = list()\n",
    "        self._ID = 0\n",
    "        \n",
    "        for doc_id, doc_text in enumerate(documents):\n",
    "            self.DOCS.append(doc_text)\n",
    "            \n",
    "            if self.split_by is not None:\n",
    "                splitter = self.__SPLITTERS_MAP[self.split_by]\n",
    "                \n",
    "                for chunk_id, chunk_text in enumerate(splitter(doc_text)):\n",
    "                    text_unit = TextUnit(_id=self._ID,\n",
    "                                         doc_id=doc_id,\n",
    "                                         chunk_id='%s_%s' % (doc_id, chunk_id),\n",
    "                                         text=chunk_text\n",
    "                                        )\n",
    "                    self.__set_vectors(text_unit)\n",
    "                    \n",
    "                    self.D.append(text_unit)\n",
    "                    self._ID += 1\n",
    "                    \n",
    "            else:\n",
    "                text = self.__normalizer(doc_text)\n",
    "                text_unit = TextUnit(_id=self._ID,\n",
    "                                     doc_id=doc_id,\n",
    "                                     chunk_id=-1,\n",
    "                                     text=text\n",
    "                                    )\n",
    "                self.__set_vectors(text_unit)\n",
    "            \n",
    "                self.D.append(text_unit)\n",
    "                self._ID += 1\n",
    "                        \n",
    "    def __build_inverted_index(self):\n",
    "        self.__INV_IDX = defaultdict(dict)\n",
    "\n",
    "        for i, unit in enumerate(self.D):\n",
    "            for word in unit.text.split():\n",
    "                if self.__INV_IDX[word].get(i) is None:\n",
    "                    self.__INV_IDX[word][i] = 1\n",
    "\n",
    "                else:\n",
    "                    self.__INV_IDX[word][i] += 1\n",
    "                    \n",
    "    def __set_vectors(self, unit):\n",
    "        if self.w2v_model is not None:\n",
    "            unit.set_w2v(self.w2v_model)\n",
    "            \n",
    "        if self.d2v_model is not None:\n",
    "            unit.set_d2v(self.d2v_model)\n",
    "            \n",
    "    def __check_bm25(self):\n",
    "        if '__INV_IDX' not in self.__dict__:\n",
    "            self.__build_inverted_index()\n",
    "            \n",
    "        if '__bm25_ready' not in self.__dict__:\n",
    "            self.__prepare_bm25()\n",
    "            \n",
    "    def __check_w2v(self):\n",
    "        if self.w2v_model is None:\n",
    "            raise Exception('w2v model not found')\n",
    "            \n",
    "    def __check_d2v(self):\n",
    "        if self.d2v_model is None:\n",
    "            raise Exception('d2v model not found')\n",
    "            \n",
    "    def __check_blend(self):\n",
    "        self.__check_bm25()\n",
    "        self.__check_w2v()\n",
    "        \n",
    "    def __prepare_bm25(self):\n",
    "        self.__k1 = 2.0\n",
    "        self.__b = 0.75\n",
    "        self.__N = len(self.D)\n",
    "        self.__avgdl = np.mean([unit.len for unit in self.D])\n",
    "        self.__bm25_ready = True\n",
    "        \n",
    "    def __compute_bm25(self, qf, dl, n):\n",
    "        first = (self.__N - n + 0.5) / (n + 0.5)\n",
    "        second = (self.__k1 + 1) * qf\n",
    "        third = qf + self.__k1 * (1 - self.__b + self.__b * (dl / self.__avgdl))\n",
    "        return np.log(first) * (second / third)\n",
    "    \n",
    "    def __sim_bm25(self, query_unit, unit, model):\n",
    "        score = 0\n",
    "        dl = unit.len\n",
    "\n",
    "        for word in query_unit.text.split():\n",
    "            if word in self.__INV_IDX:\n",
    "                qf = self.__INV_IDX[word][unit._id] if self.__INV_IDX[word].get(unit._id) is not None else 0\n",
    "                n = len(self.__INV_IDX[word])\n",
    "                score += self.__compute_bm25(qf, dl, n)\n",
    "\n",
    "        return score\n",
    "            \n",
    "    def __sim_cosine(self, query_unit, unit, model):\n",
    "        _dot = np.dot(query_unit.__dict__[model], unit.__dict__[model])\n",
    "        lnorm = np.sqrt(np.sum(query_unit.__dict__[model]**2))\n",
    "        rnorm = np.sqrt(np.sum(unit.__dict__[model]**2))\n",
    "        return _dot / (lnorm * rnorm)\n",
    "    \n",
    "    def __sigmoid(self, x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "    \n",
    "    def __sim_blend(self, query_unit, unit, model):\n",
    "        return (0.5 * self.__sigmoid(self.__sim_bm25(query_unit, unit, model)) + \\\n",
    "                0.5 * self.__sim_cosine(query_unit, unit, 'w2v')) / 2\n",
    "    \n",
    "    def __search(self, query_unit, algo):\n",
    "        self.__ALGOS_CHECK_MAP[algo]()\n",
    "        \n",
    "        similarity = self.__ALGOS_SIM_MAP[algo]\n",
    "        \n",
    "        scores = list()\n",
    "\n",
    "        for i, unit in enumerate(self.D):\n",
    "            scores.append((i, similarity(query_unit, unit, algo)))\n",
    "        \n",
    "        return scores\n",
    "        \n",
    "    def __sort_output_old(self, scores, top_n):\n",
    "        output = dict()\n",
    "        _sorted = [(self.D[_id].doc_id, {'score': score, 'text': self.DOCS[self.D[_id].doc_id]}) \\\n",
    "                   for _id, score in sorted(scores, key=lambda x: x[1], reverse=True)\n",
    "                  ]\n",
    "        \n",
    "        for _id, score in _sorted:\n",
    "            if len(output) >= top_n:\n",
    "                return output\n",
    "            \n",
    "            if _id not in output:\n",
    "                output[_id] = score\n",
    "        \n",
    "        return output\n",
    "    \n",
    "    def __sort_output(self, scores, top_n):\n",
    "        _sorted = [(self.D[_id].doc_id, {'score': score, 'text': self.DOCS[self.D[_id].doc_id]}) \\\n",
    "                   for _id, score in sorted(scores, key=lambda x: x[1], reverse=True)\n",
    "                  ][:top_n]\n",
    "        return {k: v for k, v in _sorted}\n",
    "    \n",
    "    def __prepare_query_unit(self, query):\n",
    "        query = self.__normalizer(query)\n",
    "        query_unit = TextUnit.from_text(query)\n",
    "        self.__set_vectors(query_unit)\n",
    "        return query_unit\n",
    "        \n",
    "    def search(self, query, top_n=5, algo='w2v', split_by=None):\n",
    "        \"\"\"\n",
    "        query: str: query\n",
    "        top_n: int: return `top_n` best results\n",
    "        algo: str: ['bm25', 'w2v', 'd2v', 'blend']: algorithm used (blend=bm25+w2v)\n",
    "        split_by: str: [None, 'sentences', 'words']: `query` splitting method\n",
    "        \"\"\"\n",
    "        \n",
    "        if split_by is None:\n",
    "            query_unit = self.__prepare_query_unit(query)\n",
    "            return self.__sort_output(self.__search(query_unit, algo), top_n)\n",
    "        \n",
    "        else:\n",
    "            query_units = list()\n",
    "            scores = dict()\n",
    "            \n",
    "            splitter = self.__SPLITTERS_MAP[split_by]\n",
    "                \n",
    "            for chunk_id, chunk_text in enumerate(splitter(query)):\n",
    "                text_unit = TextUnit(_id=None,\n",
    "                                     doc_id=None,\n",
    "                                     chunk_id=None,\n",
    "                                     text=chunk_text\n",
    "                                    )\n",
    "                self.__set_vectors(text_unit)\n",
    "\n",
    "                query_units.append(text_unit)\n",
    "            \n",
    "            for query_unit in query_units:\n",
    "                scores.update(self.__sort_output(self.__search(query_unit, algo), top_n))\n",
    "            \n",
    "            scores = {k: scores[k] for k in sorted(scores, key=lambda x: scores.get(x)['score'], reverse=True)[:top_n]}\n",
    "            \n",
    "            return scores\n",
    "    \n",
    "    def score(self, X, algos, top_n=5, split_by=None):\n",
    "        \"\"\"\n",
    "        X: list: ids of queries \n",
    "        Y: list: ids of true responses\n",
    "        \"\"\"\n",
    "        \n",
    "        res = defaultdict(list)\n",
    "\n",
    "        for algo in algos:\n",
    "            for i, x in enumerate(X):\n",
    "                if i in self.search(x, top_n=top_n+1, algo=algo, split_by=split_by):\n",
    "                    res[algo].append(1)\n",
    "\n",
    "                else:\n",
    "                    res[algo].append(0)\n",
    "\n",
    "            res[algo] = np.mean(res[algo])\n",
    "\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w2v_model = Word2Vec.load('w2v_model/araneum_none_fasttextskipgram_300_5_2018.model')\n",
    "d2v_model = Doc2Vec.load('d2v_model/d2v_model.model') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Инициализируем корпус без разбиения документов на фрагменты / параграфы<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corpus = Corpus(w2v_model=w2v_model, d2v_model=d2v_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1.91 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "corpus.build(RESPONSES_LEM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пример работы поиска<br>\n",
    "*Ясно, что, вообще говоря, необходимо было ввести функционал лемматизации входящего в `.search()` запроса, однако я не делал этого, потому как вся коллекция уже и так лемматизирована и для необходимого тестирования качества этого достаточно*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doc_id: 1364\n",
      "text: Для граждан России режим въезда на Украину — безвизовый, только по загранпаспортам (въезд по общегражданским (внутренним) паспортам был закрыт с 1 марта 2015 г. решением украинского правительства). При въезде на Украину с 1 января 2018 года необходимо сдавать отпечатки пальцев (биометрию). Россиянам и другим безвизовым гражданам без регистрации по месту временного пребывания можно находится на территории Украины до 90 дней\n",
      "\n",
      "doc_id: 0\n",
      "text: Добрый вечер!Из Вашего вопроса вообще ничего не ясно.Ваш сын по ВНЖ в Нижегородской обл. сделал временную  на 90 дней в Ростове? Так? Или в чем заключается вопрос?С ув., АлёнаМиграционный юристРостов-на-Дону \n",
      "\n",
      "doc_id: 874\n",
      "text: К сожалению нет, долг все равно останется, т.к. он накоплен за тот период когда вы были там прописаны. И при смене прописки УК вправе вам предъявить иск по новому месту жительства. \n",
      "\n",
      "doc_id: 1383\n",
      "text: Добрый вечер. Да, должны. НДС — до 25 января 2018 г., Налог на прибыль до 28 марта 2018 г.\n",
      "\n",
      "doc_id: 1088\n",
      "text: Здравствуйте.но мне хотелось бы узнать прав я или нет был, может я не так поставил машину что помешал ему выехать, но я отсчитал до его машины было 4-4.5метров что дает большое место для выезда, поэтому хотелось понять кто прав все таки и должны ли мне сразу сотрудники гибдд сообщить что я виновник ???эдуардПравы Вы, как стоял Ваш автомобиль не важно. Так как водитель скрылся будет проводиться административное расследование по ст 12.27 КОАП, \n",
      "\n",
      "Wall time: 575 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for _id in corpus.search(QUERIES_LEM[0], algo='bm25'):\n",
    "    print('doc_id: %s\\ntext: %s\\n' % (_id, RESPONSES[_id]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Эксперимент на всей коллекции"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 6min 47s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "SCORES = corpus.score(X=QUERIES_LEM,\n",
    "                      algos=['w2v', 'bm25', 'd2v']\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(list,\n",
       "            {'bm25': 0.509393063583815,\n",
       "             'd2v': 0.06430635838150289,\n",
       "             'w2v': 0.3619942196531792})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SCORES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь повторим эксперимент, разбивая документы на фрагменты а именно, параграфы по одному предложению (кол-во чанков выбрано экспериментально)<br>\n",
    "*Я не тестировал таким образом BM25, т.к. для этой функции разбиение имеет малый смысл, а общее время исполнения много больше в сравнении с векторными методами*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corpus2 = Corpus(split_by='sentences', n_chunks=3, w2v_model=w2v_model, d2v_model=d2v_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2.67 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "corpus2.build(RESPONSES_LEM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3min 37s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "SCORES_CHUNKED = corpus2.score(X=QUERIES_LEM,\n",
    "                               algos=['w2v', 'd2v'],\n",
    "                               split_by='sentences'\n",
    "                               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(list,\n",
       "            {'bm25': 0,\n",
       "             'd2v': 0.024566473988439308,\n",
       "             'w2v': 0.36488439306358383})"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SCORES_CHUNKED['bm25'] = 0\n",
    "SCORES_CHUNKED"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Результаты двух экспериментов на графике"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_scores(scores, titles):\n",
    "    KEYS = ['w2v', 'bm25', 'd2v']\n",
    "    \n",
    "    for score, title in zip(scores, titles):\n",
    "        plt.plot(range(len(KEYS)), [score[k] for k in KEYS], alpha=0.7, label=title)\n",
    "    \n",
    "    plt.xticks(range(len(KEYS)), KEYS)\n",
    "    plt.xlabel('Algo')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x231239f50b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_scores([SCORES, SCORES_CHUNKED], ['Full text', 'Chunked'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Как видно, поиск по разбитым и не разбитым документам показал идентичный уровень качества (BM25 при разбиении не тестировался)<br>\n",
    "Касательно алгоритмов, наивысшего результата (~0.5) удалось добиться с помощью BM25<br>\n",
    "Векторные модели показали результат несколько хуже, а `doc2vec` (1000 эпох на лемматизированной коллекции) оказался чрезвычайно плох<br>\n",
    "В целом решаемая задача кажется трудной, ввиду часто большого размера входящих запросов и неочевидного соответствия между содержанием вопросов и ответов  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
